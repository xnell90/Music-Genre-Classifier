{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: This notebook is a continuation of the exploratory_data_analysis notebook. For more information on that topic. please feel free to look at exploratory_data_analysis.ipynb** \n",
    "\n",
    "After exploring and analyzing the music dataset, we hypothesized that the best model that can classify a song's or music track's genre will be the convolutional neural network. To justify why it might be the best choice for our supervised learning problem, let's take a look at an example mel-spectrogram.\n",
    "\n",
    "<center><img src=\"example_mel-spectrogram.png\" style=\"width:600px;height:450px\"></center>\n",
    "\n",
    "As you can see in this image,\n",
    "* There are multiple squiggly lines at the lower segment of the image so it indicates that there is a vocalist in the music track.\n",
    "* There are many bright vertical lines that is consistently spaced so it means that the music track has a consistent beat.\n",
    "\n",
    "If the mel-spectrogram was shifted slightly to the left by one pixel, then intuitively, it looks like the same mel-spectrogram. Hence, if the shifted mel-spectrogram was translated to an audio file, then it would sound the same as the original. This means that if we need a model that can identify a track's genre, then it must be translationally invariant. Fortunately, the convolutional neural network model is designed to be translationally invariant because it inherently uses a filter that passes through an image to perform a convolutional operation. Fore more details about CNNs, see https://en.wikipedia.org/wiki/Convolutional_neural_network.\n",
    "\n",
    "Before we can use CNNs to classify a song's genre, we first need to preprocess our music dataset so that it can be easily used as input for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from librosa import load, power_to_db\n",
    "from librosa.feature import melspectrogram\n",
    "\n",
    "def compute_melspectrogram(file_location):\n",
    "    y, sampling_rate = load(file_location)\n",
    "    melspectrogram_db = power_to_db(\n",
    "        melspectrogram(y=y, sr=sampling_rate), \n",
    "        ref=np.max\n",
    "    )\n",
    "\n",
    "    return melspectrogram_db\n",
    "\n",
    "#One Hot Encode The Genres\n",
    "music_df = pd.read_csv('../data/metadata.csv')\n",
    "genre_df = pd.get_dummies(music_df.genre, prefix='is-')\n",
    "\n",
    "music_df = music_df.join(genre_df)\n",
    "music_df.drop(['genre'], axis=1, inplace=True)\n",
    "\n",
    "#Convert File Locations To Melspectrograms\n",
    "music_df[\"melspectrograms\"] = music_df[\"file_location\"].apply(compute_melspectrogram)\n",
    "music_df.drop(['file_location'], axis=1, inplace=True)\n",
    "\n",
    "#Save Predictor Variables As Numpy Arrays\n",
    "melspectrograms = np.array(\n",
    "    list(music_df['melspectrograms'])\n",
    ")\n",
    "extracted_features = np.array(\n",
    "    music_df[['tempo', 'zero_crossing_rate', 'average_spectral_flatness']]\n",
    ")\n",
    "\n",
    "np.save('melspectrograms.npy', melspectrograms)\n",
    "np.save('extracted_features.npy', extracted_features)\n",
    "\n",
    "#Save Response Variables As Numpy Arrays\n",
    "one_hot_encoded_genres = np.array(genre_df)\n",
    "np.save('one_hot_encoded_genres.npy', one_hot_encoded_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coming Soon ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation For CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coming Soon ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coming Soon ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation For Modified CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coming Soon ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coming Soon ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation For Pretrained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coming Soon ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
